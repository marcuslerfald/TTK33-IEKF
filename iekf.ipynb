{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IEKF implementation for differential drive vehicle.\n",
    "\n",
    "Authors: Håvard Brenne and Marcus Lerfald"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin, cos, remainder\n",
    "import numpy as np\n",
    "    \n",
    "class Vehicle:\n",
    "    def __init__(self, measurement_stds, T=0.01):\n",
    "        # x: x, y, theta, v\n",
    "        # u: a, omega\n",
    "        self.T = T\n",
    "        self.measurement_stds = measurement_stds\n",
    "\n",
    "    def f(self, x, u, enable_noise=True):\n",
    "        # Zero-order hold discretization. x_dot ≈ 1/dt(x_k+1 - x_k)\n",
    "        # Ad = I + A*dt, Bd = B*dt\n",
    "        # x_dot = v*cos(theta)\n",
    "        # y_dot = v*sin(theta)\n",
    "        # theta_dot = omega\n",
    "        # v_dot = a\n",
    "        B = np.array([\n",
    "            [0, 0],\n",
    "            [0, 0],\n",
    "            [0, 1],\n",
    "            [1, 0]\n",
    "        ])\n",
    "        A = np.zeros((x.size, x.size))\n",
    "        A[0,3] = cos(x[2])\n",
    "        A[1,3] = sin(x[2])\n",
    "        \n",
    "        Ad = np.eye(x.size) + A*self.T\n",
    "        Bd = B*self.T\n",
    "        x_new = Ad @ x + Bd @ (u + enable_noise * np.random.normal(0, np.flip(self.measurement_stds[-2:])))\n",
    "        x_new[2] = remainder(x_new[2], 2*np.pi)  # Limit to -pi~pi\n",
    "        return x_new\n",
    "\n",
    "    def F(self, x):\n",
    "        return np.array([\n",
    "            [1, 0, -x[3]*self.T*sin(x[2]), self.T*cos(x[2])],\n",
    "            [0, 1, x[3]*self.T*cos(x[2]), self.T*sin(x[2])],\n",
    "            [0, 0, 1, 0],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "\n",
    "    def g(self, x, enable_noise=True):\n",
    "        Cd = np.array([\n",
    "            [1, 0, 0, 0],\n",
    "            [0, 1, 0, 0]\n",
    "        ])\n",
    "        return Cd @ x + enable_noise*np.random.normal(0, self.measurement_stds[:2]).T\n",
    "\n",
    "    def G(self):\n",
    "        return np.array([\n",
    "            [1, 0, 0, 0],\n",
    "            [0, 1, 0, 0]\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the IEKF and the EKF, we consider the case of normal and high noise levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low noise in position, angular rate and linear acceleration\n",
    "# Long simulation\n",
    "\n",
    "measurement_stds = np.array([0.3,0.3,0.05,0.1])\n",
    "num_iterations = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High position, angular rate and linear acceleration noise\n",
    "# Long simulation\n",
    "\n",
    "measurement_stds = np.array(([3.0,3.0,0.5,1.0]))\n",
    "num_iterations = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import remainder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)   # For repeatability\n",
    "\n",
    "num_states = 4\n",
    "num_measurements = 2\n",
    "max_iekf_iterations = 10\n",
    "\n",
    "position_update_freq = 100\n",
    "timesteps = np.arange(0,num_iterations)\n",
    "\n",
    "trajectory = np.empty((0,num_states), float)\n",
    "ground_truth = np.empty((0,num_states), float)\n",
    "NIS = np.empty((0,1), float)\n",
    "NEES = np.empty((0,1), float)\n",
    "\n",
    "# Initialize model\n",
    "x0 = np.array([0]*num_states)\n",
    "P0 = 1e-4*np.eye(num_states)\n",
    "gt = x0\n",
    "\n",
    "vehicle = Vehicle(measurement_stds=measurement_stds)\n",
    "\n",
    "u = np.vstack((num_iterations*[0.1], num_iterations*[0.5]))\n",
    "u[0, num_iterations//4:3*num_iterations//4] = 0 # Drive in a circle for 3/5 the simulation\n",
    "\n",
    "x_prev = x0\n",
    "P_prev = P0\n",
    "\n",
    "Q = np.diag([1e-1,1e-1,1e-2,5e-2])**2\n",
    "R = np.diag(measurement_stds[:2])**2\n",
    "\n",
    "G = vehicle.G()\n",
    "\n",
    "k = 0\n",
    "while k <= num_iterations - 1:\n",
    "    \n",
    "    # Prediction step\n",
    "    P_pred = vehicle.F(x_prev) @ P_prev @ vehicle.F(x_prev).T + Q\n",
    "    x_pred = vehicle.f(x_prev, u[:,k])\n",
    "    \n",
    "    # Kalman gain and covariance\n",
    "    S = G @ P_pred @ G.T + R    # Innovation covariance\n",
    "    K = np.linalg.solve(S.T, (P_pred @ G.T).T).T   # Faster than P_pred @ G.T @ np.linalg.inv(G @ P_pred @ G.T + R)\n",
    "    P = (np.eye(num_states) - K @ G) @ P_pred\n",
    "    P_prev = P\n",
    "    \n",
    "    x_noisy = vehicle.f(gt, u[:,k], enable_noise=True)\n",
    "    gt = vehicle.f(gt, u[:,k], enable_noise=False)\n",
    "    if (k % position_update_freq == 0):\n",
    "        # Update step\n",
    "        x_op = x_pred\n",
    "        y = vehicle.g(x_noisy, enable_noise=True)\n",
    "        i = 1\n",
    "        while i <= max_iekf_iterations:\n",
    "            if i != 1:\n",
    "                x_op = x\n",
    "            y_op = vehicle.g(x_op, enable_noise=False)\n",
    "            x = x_pred + K @ (y - y_op - G @ (x_pred - x_op))\n",
    "            x[2] = remainder(x[2], 2*np.pi)\n",
    "            if np.linalg.norm(x - x_op) < 1e-10:\n",
    "                break\n",
    "            i += 1\n",
    "        y = vehicle.g(x, enable_noise=True)\n",
    "        g = vehicle.g(x, enable_noise=False)\n",
    "        innovation = y - g\n",
    "        x_prev = x\n",
    "\n",
    "        NIS = np.vstack((NIS, innovation.T @ np.linalg.solve(S, innovation)))\n",
    "    else:\n",
    "        x = x_pred\n",
    "        x[2] = remainder(x[2], 2*np.pi)\n",
    "        x_prev = x\n",
    "\n",
    "    # Store estimated trajectory\n",
    "    trajectory = np.vstack((trajectory, x))\n",
    "\n",
    "    # Store ground truth\n",
    "    ground_truth = np.vstack((ground_truth, gt))\n",
    "    estimation_error = gt - x\n",
    "    estimation_error[2] = remainder(estimation_error[2], 2*np.pi) # Limit to -pi~pi\n",
    "\n",
    "    NEES = np.vstack((NEES, estimation_error.T @ np.linalg.solve(P, estimation_error)))\n",
    "\n",
    "    # Count iterations\n",
    "    k+=1\n",
    "ANIS = np.mean(NIS)\n",
    "ANEES = np.mean(NEES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.distributions import chi2\n",
    "\n",
    "# Using https://arxiv.org/abs/1807.08855 for tuning\n",
    "print(f\"ANIS: {ANIS:.2f}\")\n",
    "print(f\"ANEES: {ANEES:.2f}\")\n",
    "\n",
    "confidence = 0.95\n",
    "alpha = 1 - confidence\n",
    "NEES_bounds = [chi2.ppf(alpha/2, df=num_states), chi2.ppf(1-alpha/2, df=num_states)]\n",
    "NIS_bounds = [chi2.ppf(alpha/2, df=num_measurements), chi2.ppf(1-alpha/2, df=num_measurements)]\n",
    "\n",
    "NIS_within_bounds = ((NIS_bounds[0] < NIS) & (NIS < NIS_bounds[1])).sum()/NIS.size\n",
    "NEES_within_bounds = ((NEES_bounds[0] < NEES) & (NEES < NEES_bounds[1])).sum()/NEES.size\n",
    "\n",
    "print(f\"NIS within {confidence*100:.2f} percentile: {NIS_within_bounds*100:.2f}%\")\n",
    "print(f\"NEES within {confidence*100:.2f} percentile: {NEES_within_bounds*100:.2f}%\")\n",
    "\n",
    "print(f\"RMSE in position estimate: {np.sqrt(np.mean((trajectory[:,:2]-ground_truth[:,:2])**2)):.3f}\")\n",
    "\n",
    "print(f\"Maximum error in position estimate: {np.max(np.sqrt((trajectory[:,:2]-ground_truth[:,:2])**2)):.2f}\")\n",
    "\n",
    "# Plotting\n",
    "plt.rcParams['figure.figsize'] = [15, 15]\n",
    "fig, axs = plt.subplots(4, 2)\n",
    "axs[0,0].plot(trajectory[:,0], trajectory[:,1])\n",
    "axs[0,0].plot(trajectory[::position_update_freq,0], trajectory[::position_update_freq,1], 'bo')\n",
    "axs[0,0].set_title('Estimated position in XY plane')\n",
    "axs[0,1].plot(trajectory[:,0], trajectory[:,1], ground_truth[:,0], ground_truth[:,1])\n",
    "axs[0,1].plot(trajectory[::position_update_freq,0], trajectory[::position_update_freq,1], 'bo')\n",
    "axs[0,1].plot(ground_truth[::position_update_freq,0], ground_truth[::position_update_freq,1], 'ro')\n",
    "axs[0,1].set_title('Estimated position in XY plane vs ground truth')\n",
    "states = [\"x position\",\"y position\",r\"$\\theta$\",\"velocity\"]\n",
    "for i in range(num_states):\n",
    "    axs[1+i//2, i%2].plot(timesteps, trajectory[:,i], ground_truth[:,i])\n",
    "    axs[1+i//2, i%2].set_title(f'Estimated {states[i]} vs ground truth')\n",
    "axs[3,0].plot(timesteps[::position_update_freq], NIS[:,0])\n",
    "axs[3,0].axhline(y = num_measurements, color = 'r', linestyle = '-')\n",
    "axs[3,0].set_title('NIS')\n",
    "axs[3,0].axhline(y = num_measurements, color = 'r', linestyle = '-')\n",
    "[axs[3,0].axhline(y = i, color = 'b', linestyle = '-') for i in NIS_bounds]\n",
    "axs[3,1].plot(timesteps, NEES[:,0])\n",
    "axs[3,1].set_title('NEES')\n",
    "axs[3,1].axhline(y = num_states, color = 'r', linestyle = '-')\n",
    "[axs[3,1].axhline(y = i, color = 'b', linestyle = '-') for i in NEES_bounds]\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the IEKF, we see results similar to the EKF. When increasing the noise in position measurements, angular velocity and linear acceleration, the estimates will be degraded and deviate sooner.\n",
    " \n",
    "For the simulation with low noise, the IEKF and EKF have almost identical RMSE. The NIS and NEES are also very similar.\n",
    "The reason for this is the linear measurement model. Since $G=C_d$ is constant, we do not get a new Kalman gain each iteration and our IEKF correction steps reduces to a regular EKF correction step:\n",
    "\n",
    "Let $x^k$ indicate correction iteration $k$ of the IEKF.\n",
    "$$\\hat x^2 = \\check x + K(y-y_{op}^2 - G(\\check x - x_{op}^2) \\ | \\ y_{op} = g(x_{op}, 0)=G x_{op}$$\n",
    "$$=\\check x + K(y-G x_{op}^2 - G(\\check x - x_{op}^2) \\ | \\ x_{op}^k = \\hat x^{k-1}$$\n",
    "$$=\\check x + K(y-G \\hat x^1 - G(\\check x - \\hat x^1)$$\n",
    "$$=\\check x + K(y- G \\check x + G \\hat x^1 - G \\hat x^1)$$\n",
    "$$=\\check x + K(y- G \\check x)$$\n",
    "$$=\\check x + K(y- C_d \\check x)$$\n",
    "\n",
    "Which is the EKF correction step.\n",
    "At this point, the IEKF will stop iterating, because there is no change in $\\hat x$:\n",
    "$$\\hat x^2 - \\hat x^1 = \\check x + K(y- G \\check x) - (\\check x + K(y-y_{op}^1 - G(\\check x - x_{op}^1))$$\n",
    "$$= \\check x + K(y- G \\check x) - \\check x - K (y-g(\\check x, 0)) + G(\\check x - \\check x)$$\n",
    "$$=0$$\n",
    "\n",
    "For models with stronger nonlinearities, this is not the case and we would expect a significant performance increase with an IEKF.\n",
    "This is the main advantage of the IEKF, as the linearization point can converge to the mode of the full Bayesian posterior, instead of the mean as with the EKF, resulting in lower divergance rate.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
