{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EKF implementation for differential drive vehicle.\n",
    "\n",
    "Authors: Håvard Brenne and Marcus Lerfald"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin, cos, remainder\n",
    "import numpy as np\n",
    "    \n",
    "class Vehicle:\n",
    "    def __init__(self, measurement_stds, T=0.01):\n",
    "        # x: x, y, theta, v\n",
    "        # u: a, omega\n",
    "        self.T = T\n",
    "        self.measurement_stds = measurement_stds\n",
    "\n",
    "    def f(self, x, u, enable_noise=True):\n",
    "        # Zero-order hold discretization. x_dot ≈ 1/dt(x_k+1 - x_k)\n",
    "        # Ad = I + A*dt, Bd = B*dt\n",
    "        # x_dot = v*cos(theta)\n",
    "        # y_dot = v*sin(theta)\n",
    "        # theta_dot = omega\n",
    "        # v_dot = a\n",
    "        B = np.array([\n",
    "            [0, 0],\n",
    "            [0, 0],\n",
    "            [0, 1],\n",
    "            [1, 0]\n",
    "        ])\n",
    "        A = np.zeros((x.size, x.size))\n",
    "        A[0,3] = cos(x[2])\n",
    "        A[1,3] = sin(x[2])\n",
    "        \n",
    "        Ad = np.eye(x.size) + A*self.T\n",
    "        Bd = B*self.T\n",
    "        x_new = Ad @ x + Bd @ (u + enable_noise * np.random.normal(0, np.flip(self.measurement_stds[-2:])))\n",
    "        x_new[2] = remainder(x_new[2], 2*np.pi)  # Limit to -pi~pi\n",
    "        return x_new\n",
    "\n",
    "    def F(self, x):\n",
    "        return np.array([\n",
    "            [1, 0, -x[3]*self.T*sin(x[2]), self.T*cos(x[2])],\n",
    "            [0, 1, x[3]*self.T*cos(x[2]), self.T*sin(x[2])],\n",
    "            [0, 0, 1, 0],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "\n",
    "    def g(self, x, enable_noise=True):\n",
    "        Cd = np.array([\n",
    "            [1, 0, 0, 0],\n",
    "            [0, 1, 0, 0]\n",
    "        ])\n",
    "        return Cd @ x + enable_noise*np.random.normal(0, self.measurement_stds[:2]).T\n",
    "\n",
    "    def G(self):\n",
    "        return np.array([\n",
    "            [1, 0, 0, 0],\n",
    "            [0, 1, 0, 0]\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four different nosie levels for position, angular rate and linear acceleration measurements are compared. Initialize one of the corresponding measurements noise standard deviations below. \n",
    "\n",
    "Resulting plots of the experiments are saved below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low noise in position, angular rate and linear acceleration\n",
    "\n",
    "measurement_stds = np.array([0.3,0.3,0.05,0.1])\n",
    "num_iterations = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High position noise, low angular rate and linear acceleration noise\n",
    "\n",
    "measurement_stds = np.array(([3.0,3.0,0.05,0.1]))\n",
    "num_iterations = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low position noise, high angular rate and linear acceleration noise\n",
    "\n",
    "measurement_stds = np.array(([0.3,0.3,0.1,0.2]))\n",
    "num_iterations = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High position, angular rate and linear acceleration noise\n",
    "\n",
    "measurement_stds = np.array(([3.0,3.0,0.1,0.2]))\n",
    "num_iterations = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)   # For repeatability\n",
    "\n",
    "num_states = 4\n",
    "num_measurements = 2\n",
    "\n",
    "position_update_freq = 100\n",
    "timesteps = np.arange(0,num_iterations)\n",
    "\n",
    "trajectory = np.empty((0,num_states), float)\n",
    "ground_truth = np.empty((0,num_states), float)\n",
    "NIS = np.empty((0,1), float)\n",
    "NEES = np.empty((0,1), float)\n",
    "\n",
    "# Initialize model\n",
    "x0 = np.array([0]*num_states)\n",
    "P0 = 1e-3*np.eye(num_states)\n",
    "gt = x0\n",
    "\n",
    "vehicle = Vehicle(measurement_stds=measurement_stds)\n",
    "\n",
    "u = np.vstack((num_iterations*[0.1], num_iterations*[0.5]))\n",
    "u[0, num_iterations//4:3*num_iterations//4] = 0 # Drive in a circle for 3/5 the simulation\n",
    "\n",
    "x_prev = x0\n",
    "P_prev = P0\n",
    "\n",
    "Q = np.diag([2.2e-1,2.2e-1,2.5e-3,5e-3])**2\n",
    "R = np.diag(measurement_stds[:2])**2\n",
    "\n",
    "G = vehicle.G()\n",
    "\n",
    "k = 0\n",
    "while k <= num_iterations - 1:\n",
    "    \n",
    "    # Prediction step\n",
    "    P_pred = vehicle.F(x_prev) @ P_prev @ vehicle.F(x_prev).T + Q\n",
    "    x_pred = vehicle.f(x_prev, u[:,k])\n",
    "    \n",
    "    x_noisy = vehicle.f(gt, u[:,k], enable_noise=True)\n",
    "    gt = vehicle.f(gt, u[:,k], enable_noise=False)\n",
    "    if (k % position_update_freq == 0):\n",
    "        # Kalman gain and covariance\n",
    "        S = G @ P_pred @ G.T + R    # Innovation covariance\n",
    "        K = np.linalg.solve(S.T, (P_pred @ G.T).T).T   # Faster than P_pred @ G.T @ np.linalg.inv(G @ P_pred @ G.T + R)\n",
    "        P = (np.eye(num_states) - K @ G) @ P_pred\n",
    "        P_prev = P\n",
    "\n",
    "        # Update step\n",
    "        y = vehicle.g(x_noisy, enable_noise=True)\n",
    "        g = vehicle.g(x_pred, enable_noise=False)\n",
    "        innovation = y - g\n",
    "        x = x_pred + K @ innovation\n",
    "        x[2] = remainder(x[2], 2*np.pi)\n",
    "        x_prev = x\n",
    "\n",
    "        NIS = np.vstack((NIS, innovation.T @ np.linalg.solve(S, innovation)))\n",
    "\n",
    "        covariance_ellipse_axis = np.vstack((covariance_ellipse_axis, np.diag(P)[:num_measurements]))\n",
    "    else:\n",
    "        x = x_pred\n",
    "        x_prev = x\n",
    "\n",
    "    # Store estimated trajectory\n",
    "    trajectory = np.vstack((trajectory, x))\n",
    "\n",
    "    # Store ground truth\n",
    "    ground_truth = np.vstack((ground_truth, gt))\n",
    "    estimation_error = gt - x\n",
    "    estimation_error[2] = remainder(estimation_error[2], 2*np.pi) # Limit to -pi~pi\n",
    "\n",
    "    NEES = np.vstack((NEES, estimation_error.T @ np.linalg.solve(P, estimation_error)))\n",
    "\n",
    "    # Cunt iterations\n",
    "    k+=1\n",
    "    \n",
    "ANIS = np.mean(NIS)\n",
    "ANEES = np.mean(NEES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats.distributions import chi2\n",
    "\n",
    "# Using https://arxiv.org/abs/1807.08855 for tuning\n",
    "print(f\"ANIS: {ANIS:.2f}\")\n",
    "print(f\"ANEES: {ANEES:.2f}\")\n",
    "\n",
    "confidence = 0.95\n",
    "alpha = 1 - confidence\n",
    "NEES_bounds = [chi2.ppf(alpha/2, df=num_states), chi2.ppf(1-alpha/2, df=num_states)]\n",
    "NIS_bounds = [chi2.ppf(alpha/2, df=num_measurements), chi2.ppf(1-alpha/2, df=num_measurements)]\n",
    "\n",
    "NIS_within_bounds = ((NIS_bounds[0] < NIS) & (NIS < NIS_bounds[1])).sum()/NIS.size\n",
    "NEES_within_bounds = ((NEES_bounds[0] < NEES) & (NEES < NEES_bounds[1])).sum()/NEES.size\n",
    "\n",
    "print(f\"NIS within {confidence*100:.2f} percentile: {NIS_within_bounds*100:.2f}%\")\n",
    "print(f\"NEES within {confidence*100:.2f} percentile: {NEES_within_bounds*100:.2f}%\")\n",
    "\n",
    "print(f\"RMSE in position estimate: {np.sqrt(np.mean((trajectory[:,:2]-ground_truth[:,:2])**2)):.3f}\")\n",
    "\n",
    "print(f\"Maximum error in position estimate: {np.max(np.sqrt((trajectory[:,:2]-ground_truth[:,:2])**2)):.2f}\")\n",
    "\n",
    "# Plotting\n",
    "plt.rcParams['figure.figsize'] = [15, 15]\n",
    "fig, axs = plt.subplots(4, 2)\n",
    "axs[0,0].plot(trajectory[:,0], trajectory[:,1])\n",
    "axs[0,0].plot(trajectory[::position_update_freq,0], trajectory[::position_update_freq,1], 'bo')\n",
    "axs[0,0].set_title('Estimated position in XY plane')\n",
    "axs[0,1].plot(trajectory[:,0], trajectory[:,1], ground_truth[:,0], ground_truth[:,1])\n",
    "axs[0,1].plot(trajectory[::position_update_freq,0], trajectory[::position_update_freq,1], 'bo')\n",
    "axs[0,1].plot(ground_truth[::position_update_freq,0], ground_truth[::position_update_freq,1], 'ro')\n",
    "axs[0,1].set_title('Estimated position in XY plane vs ground truth')\n",
    "states = [\"x position\",\"y position\",r\"$\\theta$\",\"velocity\"]\n",
    "for i in range(num_states):\n",
    "    axs[1+i//2, i%2].plot(timesteps, trajectory[:,i], ground_truth[:,i])\n",
    "    axs[1+i//2, i%2].set_title(f'Estimated {states[i]} vs ground truth')\n",
    "axs[3,0].plot(timesteps[::position_update_freq], NIS[:,0])\n",
    "axs[3,0].axhline(y = num_measurements, color = 'r', linestyle = '-')\n",
    "axs[3,0].set_title('NIS')\n",
    "axs[3,0].axhline(y = num_measurements, color = 'r', linestyle = '-')\n",
    "[axs[3,0].axhline(y = i, color = 'b', linestyle = '-') for i in NIS_bounds]\n",
    "axs[3,1].plot(timesteps, NEES[:,0])\n",
    "axs[3,1].set_title('NEES')\n",
    "axs[3,1].axhline(y = num_states, color = 'r', linestyle = '-')\n",
    "[axs[3,1].axhline(y = i, color = 'b', linestyle = '-') for i in NEES_bounds]\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup, tuning process and filter consistency\n",
    "\n",
    "The process noise covariance matrix Q has been tuned for the low noise case, while R is calculated from the measurement noise standard deviations. This is often the case, because we can determine the noise in our measurement device experimentally. The Q matrix is often subject to tuning because it in general is more difficult to quantify process noise.\n",
    "\n",
    "We are using the same Q for the EKF when altering the noise, assuming the change is unknown to us. In the configuration we have used, the angular rate and linear acceleration measurement noise appears in Q because they are modeled as inputs to the system, while the position measurement noise appears in R. The R matrix is calculated from the standard deviation of the known noise in our position estimate. This is often the case in practice. In this experiment, the input noise is unknown and the Q matrix is a result of tuning by hand. Looking at the plots for normalized innovation squared (NIS) and normaized estimation error squared (NEES), the filter become overconfident in the higher noise experiments. This is due to the low covariances in the tuned Q matrix relative to the actual process noise.\n",
    "\n",
    "The tuning was done iteratively by looking at values for NIS and NEES and their confidence bounds. The NIS is chi-square distributed with an expected value equal to the number of measurements. The NEES follows a similar distribution, with expected value equal to the number of states. By calculating bounds for a confidence interval for these distributions and comparing them to the NIS/NEES, we determine the filter consistency. If the NIS/NEES falls within the bounds at a given timestep *k*, we can be 95% certain that the filter is consistent at *k*. If the NIS/NEES is *below* the lower bound, the filter is *underconfident*. If it is *above*, it is *overconfident*. We can use this fact to determine whether the elements of Q (and R) matrix should be decreased or increased. In practice, one is often limited to analyzing the NIS only because the NEES calculation depends on an available ground truth. In this experiment, we could imagine an approximate ground truth being available through RTK GNSS or motion capture systems.\n",
    "\n",
    "## Results\n",
    "### Low noise in position, angular rate and linear acceleration\n",
    "\n",
    "In the baseline test with low noise, we get the following metrics:\n",
    "\n",
    "ANIS: 1.79\n",
    "\n",
    "ANEES: 3.68\n",
    "\n",
    "NIS within 95.00 percentile: 96.20%\n",
    "\n",
    "NEES within 95.00 percentile: 96.77%\n",
    "\n",
    "RMSE in position estimate: 0.236\n",
    "\n",
    "Maximum error in position estimate: 0.88\n",
    "\n",
    "The ANIS is close to the expected value of 2.0 and the ANEES is acceptably close to 4.0. 96.20% of the NIS value fell inside the 95 percentile bounds, which is good. The NEES was a bit higher at 96.77%, but the performance was deemed suffiecent as the $RMSE=0.236$ and maximum error in estimation was quite low at 0.88m. This experiment gave us a baseline for further testing.\n",
    "\n",
    "### High position noise, low angular rate and linear acceleration noise\n",
    "\n",
    "With higher noise in position measurements, we saw larger deviations in the position estimate as expected. We get the following metrics:\n",
    "\n",
    "ANIS: 2.07\n",
    "\n",
    "ANEES: 3.75\n",
    "\n",
    "NIS within 95.00 percentile: 95.60%\n",
    "\n",
    "NEES within 95.00 percentile: 97.17%\n",
    "\n",
    "RMSE in position estimate: 0.808\n",
    "\n",
    "Maximum error in position estimate: 3.01\n",
    "\n",
    "Since we calculated our R matrix from the noise standard deviations, we were still able to achieve good filter consistency in terms of NIS. The Q matrix remained unchanged, but so were the noise parameters of inertial measurements. The NEES was therefore comparable to the baseline test. Since the noise in angular rate and linear acceleration remained low, we did not see a large increase in drift locally. However, due to the reduced confidence in the position measurements, the filter was not able to correct itself and started to drift over time, building up larger deviations. This was seen in the $RMSE=0.808$ with a maximum error of 3.01m.\n",
    "\n",
    "### Low position noise, high angular rate and linear acceleration noise\n",
    "\n",
    "We will now consider the case where the position measurement noise remains low, but the noise in angular rate and linear acceleration is large. We got the following metrics:\n",
    "\n",
    "ANIS: 3.08\n",
    "\n",
    "ANEES: 10.47\n",
    "\n",
    "NIS within 95.00 percentile: 90.20%\n",
    "\n",
    "NEES within 95.00 percentile: 60.97%\n",
    "\n",
    "RMSE in position estimate: 0.352\n",
    "\n",
    "Maximum error in position estimate: 1.58\n",
    "\n",
    "In this case the filter consistency is poor, because the increased noise is not reflected in our Q matrix for the process noise which remains unchanged. As opposed to the previous case, we now see a lot of drift on the local scale between position measurements. However, due to the low noise in the position measurements, the filter is able to correct itself and limit deviations at a global scale. This is seen in the XY-plot as abrupt changes in position whenever a new measurement is available. The $RMSE=0.352$ is worse than in the baseline test, but not as bad as in the previous experiment. The maximum error in position is also lower at 1.58m, which is expected when we have more confidence in our position measurements.\n",
    "\n",
    "### High position, angular rate and linear acceleration noise\n",
    "\n",
    "The final experiment with the EKF will consider the case when we have high noise in position, angular rate and linear acceleration measurements. The following results are obtained:\n",
    "\n",
    "ANIS: 2.34\n",
    "\n",
    "ANEES: 12.37\n",
    "\n",
    "NIS within 95.00 percentile: 94.80%\n",
    "\n",
    "NEES within 95.00 percentile: 55.23%\n",
    "\n",
    "RMSE in position estimate: 1.331\n",
    "\n",
    "Maximum error in position estimate: 4.91\n",
    "\n",
    "As expected, the filter is no longer able to follow the ground truth accurately. Due to drift at the local scale without accurate position measurements to correct for it, we end up with a trajectory which deviates from the true path up to 4.91m. The $RMSE=1.331$ is also significantly worse than in the previous experiments. When increasing the noise in both position measurements and inertial measurements simultaneously, the filter consistency in terms of NEES and overall performance is greatly reduced. The NIS remains good because we update R with our new noise model. The filter is still able to grasp the underlying shape of the trajectory, but is probably unusable in most applications without further tuning or less noisy measurements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
