{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EKF implementation for differential drive vehicle.\n",
    "\n",
    "Authors: Håvard Brenne and Marcus Lerfald"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin, cos, remainder\n",
    "import numpy as np\n",
    "    \n",
    "class Vehicle:\n",
    "    def __init__(self, x=np.array([0,0,0,0]), u=np.array([0,0]), T=0.01, measurement_stds=np.array([0.1,0.1,0.0001,0.0002])):\n",
    "        # x: x, y, theta, v\n",
    "        # u: a, omega\n",
    "        self.T = T\n",
    "        self.measurement_stds = measurement_stds\n",
    "\n",
    "        self.x = x\n",
    "        self.u = u\n",
    "        self.x_data = np.empty((0,4), float)\n",
    "        self.u_data = np.empty((0,2), float)\n",
    "\n",
    "    def f(self, x, u, enable_noise=True):\n",
    "        #Zero-order hold discretization. x_dot ≈ 1/dt(x_k+1 - x_k)\n",
    "        #Ad = I + A*dt, Bd = B*dt\n",
    "        #x_dot = v*cos(theta)\n",
    "        #y_dot = v*sin(theta)\n",
    "        #theta_dot = omega\n",
    "        #v_dot = a\n",
    "        B = np.array([\n",
    "            [0, 0],\n",
    "            [0, 0],\n",
    "            [0, 1],\n",
    "            [1, 0]\n",
    "        ])\n",
    "        A = np.zeros((self.x.size, self.x.size))\n",
    "        A[0,3] = cos(x[2])\n",
    "        A[1,3] = sin(x[2])\n",
    "        \n",
    "        Ad = np.eye(self.x.size) + A*self.T\n",
    "        Bd = B*self.T\n",
    "\n",
    "        x_new = Ad @ x + Bd @ (u + enable_noise*np.random.normal(0, self.measurement_stds[-2:]))\n",
    "        x_new[2] = remainder(x_new[2], 2*np.pi)  # Limit to -pi~pi\n",
    "        return x_new\n",
    "\n",
    "    def F(self, x):\n",
    "        return np.array([\n",
    "            [1, 0, -x[3]*self.T*sin(x[2]), self.T*cos(x[2])],\n",
    "            [0, 1, x[3]*self.T*cos(x[2]), self.T*sin(x[2])],\n",
    "            [0, 0, 1, 0],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "\n",
    "    def g(self, x, enable_noise=True):\n",
    "        Cd = np.array([\n",
    "            [1, 0, 0, 0],\n",
    "            [0, 1, 0, 0]\n",
    "        ])\n",
    "        return Cd @ x + enable_noise*np.random.normal(0, self.measurement_stds[:2]).T\n",
    "\n",
    "    def G(self):\n",
    "        return np.array([\n",
    "            [1, 0, 0, 0],\n",
    "            [0, 1, 0, 0]\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three different nosie levels for position, angular rate and linear acceleration measurements are compared. Initialize one of the corresponding measurements noise standard deviations below. \n",
    "\n",
    "In addition, a longer simulation time is performed for the last cell.\n",
    "\n",
    "Resulting plots of the experiments are saved below for easier comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low noise in position, angular rate and linear acceleration\n",
    "# Short simulation\n",
    "\n",
    "measurement_stds = np.array([0.3,0.3,0.05,0.1])\n",
    "num_iterations = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High position noise, low angular rate and linear acceleration noise\n",
    "# Short simulation\n",
    "\n",
    "measurement_stds = np.array(([3.0,3.0,0.05,0.1]))\n",
    "num_iterations = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low position noise, high angular rate and linear acceleration noise\n",
    "# Short simulation\n",
    "\n",
    "measurement_stds = np.array(([0.3,0.3,0.1,0.2]))\n",
    "num_iterations = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High position, angular rate and linear acceleration noise\n",
    "# Long simulation\n",
    "\n",
    "measurement_stds = np.array(([3.0,3.0,0.1,0.2]))\n",
    "num_iterations = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low noise in position, angular rate and linear acceleration\n",
    "# Long simulation\n",
    "\n",
    "measurement_stds = np.array([0.3,0.3,0.05,0.1])\n",
    "num_iterations = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cgitb import enable\n",
    "from time import time\n",
    "from math import remainder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)   #For repeatability\n",
    "\n",
    "num_states = 4\n",
    "num_measurements = 2\n",
    "\n",
    "position_update_freq = 100\n",
    "timesteps = np.arange(0,num_iterations)\n",
    "\n",
    "trajectory = np.empty((0,num_states), float)\n",
    "ground_truth = np.empty((0,num_states), float)\n",
    "NIS = np.empty((0,1), float)\n",
    "NEES = np.empty((0,1), float)\n",
    "\n",
    "#Initialize model\n",
    "x0 = np.array([0,0,0,0])\n",
    "P0 = 1e-4*np.eye(num_states)\n",
    "gt = x0\n",
    "\n",
    "vehicle = Vehicle(x=x0, measurement_stds=measurement_stds)\n",
    "\n",
    "u = np.vstack((num_iterations*[0.1], num_iterations*[0.5]))\n",
    "u[0, num_iterations//4:3*num_iterations//4] = 0 # Drive in a circle for 3/5 the simulation\n",
    "\n",
    "x_prev = x0\n",
    "P_prev = P0\n",
    "\n",
    "Q = np.diag(np.concatenate((np.array([2e-2,2e-2]), measurement_stds[-2:])))**2\n",
    "Q = np.diag([1e-1,1e-1,1e-2,2e-2])**2\n",
    "Q = np.diag([1e-1,1e-1,1e-2,5e-2])**2\n",
    "R = np.diag(measurement_stds[:2])**2\n",
    "\n",
    "G = vehicle.G()\n",
    "\n",
    "k = 0\n",
    "while k <= num_iterations - 1:\n",
    "    \n",
    "    #Prediction step\n",
    "    P_pred = vehicle.F(x_prev) @ P_prev @ vehicle.F(x_prev).T + Q\n",
    "    x_pred = vehicle.f(x_prev, u[:,k], enable_noise=False)\n",
    "    \n",
    "    #Kalman gain and covariance\n",
    "    S = G @ P_pred @ G.T + R    # Innovation covariance\n",
    "    K = np.linalg.solve(S.T, (P_pred @ G.T).T).T   #Faster than P_pred @ G.T @ np.linalg.inv(G @ P_pred @ G.T + R)\n",
    "    P = (np.eye(num_states) - K @ G) @ P_pred\n",
    "    P_prev = P\n",
    "    \n",
    "    gt = vehicle.f(gt, u[:,k], enable_noise=False)\n",
    "    if (k % position_update_freq == 0):\n",
    "        #Update step\n",
    "        y = vehicle.g(vehicle.f(gt, u[:,k], enable_noise=True), enable_noise=True)\n",
    "        g = vehicle.g(x_pred, enable_noise=False)\n",
    "        innovation = y - g\n",
    "        x = x_pred + K @ innovation\n",
    "        x_prev = x\n",
    "\n",
    "        NIS = np.vstack((NIS, innovation.T @ np.linalg.solve(S, innovation)))\n",
    "    else:\n",
    "        x = x_pred\n",
    "        x_prev = x\n",
    "\n",
    "    #Store estimated trajectory\n",
    "    trajectory = np.vstack((trajectory, x))\n",
    "\n",
    "    #Store ground truth\n",
    "    ground_truth = np.vstack((ground_truth, gt))\n",
    "    estimation_error = gt - x\n",
    "    estimation_error[2] = remainder(estimation_error[2], 2*np.pi) # Limit to -pi~pi\n",
    "\n",
    "    NEES = np.vstack((NEES, estimation_error.T @ np.linalg.solve(P, estimation_error)))\n",
    "\n",
    "    #Count iterations\n",
    "    k+=1\n",
    "    \n",
    "ANIS = np.mean(NIS)\n",
    "ANEES = np.mean(NEES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.distributions import chi2\n",
    "\n",
    "# Using https://arxiv.org/abs/1807.08855 for tuning\n",
    "print(f\"ANIS: {ANIS:.2f}\")\n",
    "print(f\"ANEES: {ANEES:.2f}\")\n",
    "\n",
    "confidence = 0.95\n",
    "alpha = 1 - confidence\n",
    "NEES_bounds = [chi2.ppf(alpha/2, df=num_states), chi2.ppf(1-alpha/2, df=num_states)]\n",
    "NIS_bounds = [chi2.ppf(alpha/2, df=num_measurements), chi2.ppf(1-alpha/2, df=num_measurements)]\n",
    "\n",
    "NIS_within_bounds = ((NIS_bounds[0] < NIS) & (NIS < NIS_bounds[1])).sum()/NIS.size\n",
    "NEES_within_bounds = ((NEES_bounds[0] < NEES) & (NEES < NEES_bounds[1])).sum()/NEES.size\n",
    "\n",
    "print(f\"NIS within {confidence*100:.2f} percentile: {NIS_within_bounds*100:.2f}%\")\n",
    "print(f\"NEES within {confidence*100:.2f} percentile: {NEES_within_bounds*100:.2f}%\")\n",
    "\n",
    "print(f\"RMSE in position estimate: {np.sqrt(np.mean((trajectory[:,:2]-ground_truth[:,:2])**2)):.3f}\")\n",
    "\n",
    "#Plotting\n",
    "plt.rcParams['figure.figsize'] = [15, 15]\n",
    "fig, axs = plt.subplots(4, 2)\n",
    "axs[0,0].plot(trajectory[:,0], trajectory[:,1])\n",
    "axs[0,0].plot(trajectory[::position_update_freq,0], trajectory[::position_update_freq,1], 'bo')\n",
    "axs[0,0].set_title('Estimated position in XY plane')\n",
    "axs[0,1].plot(trajectory[:,0], trajectory[:,1], ground_truth[:,0], ground_truth[:,1])\n",
    "axs[0,1].plot(trajectory[::position_update_freq,0], trajectory[::position_update_freq,1], 'bo')\n",
    "axs[0,1].plot(ground_truth[::position_update_freq,0], ground_truth[::position_update_freq,1], 'ro')\n",
    "axs[0,1].set_title('Estimated position in XY plane vs ground truth')\n",
    "states = [\"x position\",\"y position\",r\"$\\theta$\",\"velocity\"]\n",
    "for i in range(num_states):\n",
    "    axs[1+i//2, i%2].plot(timesteps, trajectory[:,i], ground_truth[:,i])\n",
    "    axs[1+i//2, i%2].set_title(f'Estimated {states[i]} vs ground truth')\n",
    "axs[3,0].plot(timesteps[::position_update_freq], NIS[:,0])\n",
    "axs[3,0].axhline(y = num_measurements, color = 'r', linestyle = '-')\n",
    "axs[3,0].set_title('NIS')\n",
    "axs[3,0].axhline(y = num_measurements, color = 'r', linestyle = '-')\n",
    "[axs[3,0].axhline(y = i, color = 'b', linestyle = '-') for i in NIS_bounds]\n",
    "axs[3,1].plot(timesteps, NEES[:,0])\n",
    "axs[3,1].set_title('NEES')\n",
    "axs[3,1].axhline(y = num_states, color = 'r', linestyle = '-')\n",
    "[axs[3,1].axhline(y = i, color = 'b', linestyle = '-') for i in NEES_bounds]\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With higher noise in position measurements, the EKF estimates of position starts diverging with increased rate. \n",
    "Higher noise in angular rate and linear acceleration measurement...\n",
    "\n",
    "The process and measurement covariance matrices Q and R have been tuned with the low noise experiment. Usually, the R matrix can be determined directly from the measured noise covariance, while Q often needs tuning.\n",
    "\n",
    "We are using the same Q for the EKF when altering the noise, assuming the change is unknown to us. In the configuration we have used, the angular rate and linear acceleration measurement noise appears in Q because they are modeled as inputs to the system, while the position measurement noise appears in R. The R matrix is calculated from the standard deviation of the known noise in our position estimate. This is often the case in practice. In this experiment, the input noise is unknown and the Q matrix is a result of tuning by hand. Looking at the plots for normalized innovation squared (NIS) and normaized estimation error squared (NEES), the filter become overconfident in the higher noise experiments. This is due to the low covariances in the tuned Q matrix relative to the actual process noise.\n",
    "\n",
    "The tuning was done iteratively by looking at values for NIS and NEES and their confidence bounds. The NIS is chi-square distributed with an expected value equal to the number of measurements. The NEES follows a similar distribution, with expected value equal to the number of states. By calculating bounds for a confidence interval for these distributions and comparing them to the NIS/NEES, we determine the filter consistency. If the NIS/NEES falls within the bounds at a given timestep *k*, we can be 95% certain that the filter is consistent at *k*. If the NIS/NEES is *below* the lower bound, the filter is *underconfident*. If it is *above*, it is *overconfident*. We can use this fact to determine whether the elements of Q (and R) matrix should be decreased or increased. In practice, one is often limited to analyzing the NIS only because the NEES calculation depends on an available ground truth. In this experiment, we could imagine an approximate ground truth being available through RTK GNSS or motion capture systems.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
